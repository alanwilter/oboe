{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a classification example to show how to use Oboe for training and testing, in the context of AutoML, i.e., do pipeline selection on the training set and then evaluate the performance of the selected model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'tensoroboe'  # 'Oboe' or 'TensorOboe'\n",
    "problem_type = 'classification'\n",
    "\n",
    "from oboe import AutoLearner, error  # This may take around 15 seconds at first run.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "data = load_iris()\n",
    "x = np.array(data['data'])\n",
    "y = np.array(data['target'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: a no-brainer use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `TensorOboe` running mode is `warm`, which means the meta-training is warm-started with pre-imputed error tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank for EM-Tucker imputation: (20, 4, 2, 2, 8, 20)\n",
      "shape of the error tensor: (551, 4, 2, 2, 8, 183)\n",
      "Loading latent factors from storage ...\n",
      "Loading saved runtime predictors ...\n"
     ]
    }
   ],
   "source": [
    "# initialize the autolearner class\n",
    "m = AutoLearner(p_type='classification', runtime_limit=50, method=method, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of training dataset: 120 data points, 4 features\n",
      "Splitting training set into training and validation ..\n",
      "Predicting pipeline running time ..\n",
      "runtime limit of initial round: 32.0 seconds\n",
      "fitting and kfold_fit_validating the best-on-average pipeline\n",
      "Pipeline fitting completed.\n",
      "Fitted an ensemble with size 1\n",
      "having a capped running time of 32 seconds\n",
      "Fitted an ensemble with size 1\n",
      "Fitted an ensemble with size 1\n",
      "Fitted an ensemble with size 1\n",
      "Fitted an ensemble with size 1\n",
      "Fitted an ensemble with size 1\n",
      "Doubling process started ...\n",
      "Fitting with ranks=(20, 4, 2, 2, 8, 18), t=32.0\n",
      "\n",
      "Single round runtime target: 32.0\n",
      "Fitting AutoLearner with maximum runtime 32.0 seconds\n",
      "Selecting an initial set of models to evaluate ...\n",
      "greedy_initialization\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "Sampling 8 entries of new row...\n",
      "pool fitting completed\n",
      "<oboe.pipeline.PipelineObject object at 0x7faca980bcd0>\n",
      "<oboe.pipeline.PipelineObject object at 0x7faca980bc70>\n",
      "<oboe.pipeline.PipelineObject object at 0x7faca980bbb0>\n",
      "<oboe.pipeline.PipelineObject object at 0x7faca980bb80>\n",
      "<oboe.pipeline.PipelineObject object at 0x7faca980bb20>\n",
      "length of sampled indices: 8\n",
      "[13985, 18377, 22769, 14168, 8312] candidate learners need to be k-fold fitted\n",
      "Fitting 5 pipelines predicted to be the best ...\n",
      "Number of candidate learners in the ensemble: 11\n",
      "\n",
      "Fitting ensemble of maximum size 11...\n",
      "Fitting a candidate learners not fitted before ..\n",
      "Pipeline fitting completed.\n",
      "Fitting a candidate learners not fitted before ..\n",
      "Pipeline fitting completed.\n",
      "Fitting a candidate learners not fitted before ..\n",
      "Pipeline fitting completed.\n",
      "Fitting a candidate learners not fitted before ..\n",
      "Pipeline fitting completed.\n",
      "Fitting a candidate learners not fitted before ..\n",
      "Pipeline fitting completed.\n",
      "Fitting a candidate learners not fitted before ..\n",
      "Pipeline fitting completed.\n",
      "Fitting a candidate learners not fitted before ..\n",
      "Pipeline fitting completed.\n",
      "Fitting a candidate learners not fitted before ..\n",
      "Pipeline fitting completed.\n",
      "Fitting a candidate learners not fitted before ..\n",
      "Pipeline fitting completed.\n",
      "Fitting a candidate learners not fitted before ..\n",
      "Pipeline fitting completed.\n",
      "cv errors: [0.04375 0.06875 0.075   0.0875  0.10625 0.06875 0.0625  0.0625  0.0625\n",
      " 0.05    0.05   ]\n",
      "Fitted an ensemble with size 5\n",
      "\n",
      "AutoLearner fitting complete.\n",
      "\n",
      "Got a new ensemble in the round with runtime target 32.0 seconds\n",
      "having a capped running time of 17 seconds\n",
      "cv errors: [0.04375 0.06875 0.075   0.0875  0.10625 0.06875 0.0625  0.0625  0.0625\n",
      " 0.05    0.05   ]\n",
      "Fitted an ensemble with size 5\n",
      "cv errors: [0.04375 0.06875 0.075   0.0875  0.10625 0.06875 0.0625  0.0625  0.0625\n",
      " 0.05    0.05   ]\n",
      "Fitted an ensemble with size 5\n",
      "cv errors: [0.04375 0.06875 0.075   0.0875  0.10625 0.06875 0.0625  0.0625  0.0625\n",
      " 0.05    0.05   ]\n",
      "Fitted an ensemble with size 5\n",
      "cv errors: [0.04375 0.06875 0.075   0.0875  0.10625 0.06875 0.0625  0.0625  0.0625\n",
      " 0.05    0.05   ]\n",
      "Fitted an ensemble with size 5\n",
      "cv errors: [0.04375 0.06875 0.075   0.0875  0.10625 0.06875 0.0625  0.0625  0.0625\n",
      " 0.05    0.05   ]\n",
      "Fitted an ensemble with size 5\n",
      "new approximate rank for the error tensor: (20, 4, 2, 2, 8, 19)\n"
     ]
    }
   ],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train, categorical=None) # TensorOboe accepts the list of feature types\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction error: 0.025000000000000022\n",
      "elapsed time: 17.90514302253723\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    "print(\"prediction error: {}\".format(error(y_test, y_predicted, 'classification')))    \n",
    "print(\"elapsed time: {}\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensemble method': 'select at most 5 pipelines with smallest cv error',\n",
       " 'base learners': [{'imputer': {'algorithm': 'SimpleImputer',\n",
       "    'hyperparameters': {'strategy': 'median'}},\n",
       "   'encoder': {'algorithm': 'OneHotEncoder',\n",
       "    'hyperparameters': {'handle_unknown': 'ignore', 'sparse': 0}},\n",
       "   'standardizer': {'algorithm': 'StandardScaler', 'hyperparameters': {}},\n",
       "   'dim_reducer': {'algorithm': 'SelectKBest', 'hyperparameters': {'k': 3}},\n",
       "   'estimator': {'algorithm': 'ExtraTrees',\n",
       "    'hyperparameters': {'min_samples_split': 1e-05, 'criterion': 'entropy'}}},\n",
       "  {'imputer': {'algorithm': 'SimpleImputer',\n",
       "    'hyperparameters': {'strategy': 'most_frequent'}},\n",
       "   'encoder': {'algorithm': None},\n",
       "   'standardizer': {'algorithm': 'StandardScaler', 'hyperparameters': {}},\n",
       "   'dim_reducer': {'algorithm': 'SelectKBest', 'hyperparameters': {'k': 1}},\n",
       "   'estimator': {'algorithm': 'GBT',\n",
       "    'hyperparameters': {'learning_rate': 0.1,\n",
       "     'max_depth': 3,\n",
       "     'max_features': 'log2'}}},\n",
       "  {'imputer': {'algorithm': 'SimpleImputer',\n",
       "    'hyperparameters': {'strategy': 'median'}},\n",
       "   'encoder': {'algorithm': None},\n",
       "   'standardizer': {'algorithm': 'StandardScaler', 'hyperparameters': {}},\n",
       "   'dim_reducer': {'algorithm': 'SelectKBest', 'hyperparameters': {'k': 1}},\n",
       "   'estimator': {'algorithm': 'GBT',\n",
       "    'hyperparameters': {'learning_rate': 0.1,\n",
       "     'max_depth': 3,\n",
       "     'max_features': 'log2'}}},\n",
       "  {'imputer': {'algorithm': 'SimpleImputer',\n",
       "    'hyperparameters': {'strategy': 'most_frequent'}},\n",
       "   'encoder': {'algorithm': None},\n",
       "   'standardizer': {'algorithm': 'StandardScaler', 'hyperparameters': {}},\n",
       "   'dim_reducer': {'algorithm': 'VarianceThreshold', 'hyperparameters': {}},\n",
       "   'estimator': {'algorithm': 'GBT',\n",
       "    'hyperparameters': {'learning_rate': 0.1,\n",
       "     'max_depth': 3,\n",
       "     'max_features': 'log2'}}},\n",
       "  {'imputer': {'algorithm': 'SimpleImputer',\n",
       "    'hyperparameters': {'strategy': 'constant'}},\n",
       "   'encoder': {'algorithm': None},\n",
       "   'standardizer': {'algorithm': None},\n",
       "   'dim_reducer': {'algorithm': 'VarianceThreshold', 'hyperparameters': {}},\n",
       "   'estimator': {'algorithm': 'GBT',\n",
       "    'hyperparameters': {'learning_rate': 0.1,\n",
       "     'max_depth': 3,\n",
       "     'max_features': 'log2'}}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: build an ensemble of models with given configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental settings\n",
    "VERBOSE = False #whether to print out information indicating current fitting progress\n",
    "N_CORES = 1 #number of cores\n",
    "RUNTIME_BUDGET = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #optional: limit the types of algorithms (not yet supported)\n",
    "# s = ['AB', 'ExtraTrees', 'GNB', 'KNN', 'RF', 'DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autolearner arguments\n",
    "autolearner_kwargs = {\n",
    "    'p_type': 'classification',\n",
    "    'method': method,\n",
    "    'runtime_limit': RUNTIME_BUDGET,\n",
    "    'verbose': VERBOSE,\n",
    "    'selection_method': 'min_variance',\n",
    "    'stacking_alg': 'greedy',\n",
    "    'n_cores': N_CORES,\n",
    "    'build_ensemble': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the autolearner class\n",
    "m = AutoLearner(**autolearner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train, categorical=None)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction error: 0.025000000000000022\n",
      "elapsed time: 7.4095470905303955\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    "print(\"prediction error: {}\".format(error(y_test, y_predicted, 'classification')))\n",
    "print(\"elapsed time: {}\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensemble method': 'select at most 5 pipelines with smallest cv error',\n",
       " 'base learners': [{'imputer': {'algorithm': 'SimpleImputer',\n",
       "    'hyperparameters': {'strategy': 'constant'}},\n",
       "   'encoder': {'algorithm': None},\n",
       "   'standardizer': {'algorithm': None},\n",
       "   'dim_reducer': {'algorithm': 'SelectKBest', 'hyperparameters': {'k': 3}},\n",
       "   'estimator': {'algorithm': 'GBT',\n",
       "    'hyperparameters': {'learning_rate': 0.025,\n",
       "     'max_depth': 3,\n",
       "     'max_features': 'log2'}}}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
